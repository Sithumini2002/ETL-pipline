{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4c9daa7e",
      "metadata": {
        "id": "4c9daa7e"
      },
      "source": [
        "# Educational Data ETL Pipeline with LLM Extraction\n",
        "\n",
        "This notebook implements a production-ready ETL pipeline for extracting structured educational data using LLMs, Pydantic validation, and MongoDB, based on the provided Python code. Each section demonstrates a key part of the pipeline, with code and explanations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346befca",
      "metadata": {
        "id": "346befca"
      },
      "source": [
        "## 1. Configuration and Directory Setup\n",
        "\n",
        "Define and initialize the configuration for the ETL pipeline, including input, output, and log directories. This section uses a dataclass for centralized configuration and ensures all directories exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7d5aac1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7d5aac1",
        "outputId": "a7871454-517e-4dbd-efff-14107484fc8e"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import os, sys\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Centralized configuration\"\"\"\n",
        "    base_dir: Path = Path(\"/content\" if 'google.colab' in sys.modules else os.getcwd())\n",
        "    input_dir: Path = None\n",
        "    logs_dir: Path = None\n",
        "    output_dir: Path = None\n",
        "    mongodb_uri: str = \"mongodb+srv://ict22006_db_user:gGgnHUqamNcU5jAy@development.ps1jayw.mongodb.net/?appName=development\"\n",
        "    database_name: str = \"edu_platform\"\n",
        "    ollama_base_url: str = \"http://localhost:11434\"\n",
        "    ollama_model: str = \"llama3\"\n",
        "    ollama_temperature: float = 0.1\n",
        "    ollama_timeout: int = 300\n",
        "    chunk_max_chars: int = 3000\n",
        "    chunk_overlap: int = 200\n",
        "    confidence_threshold: float = 0.6\n",
        "    max_retries: int = 2\n",
        "    retry_delay: int = 5\n",
        "    def __post_init__(self):\n",
        "        self.input_dir = self.base_dir / \"bci_lk\"\n",
        "        self.logs_dir = self.base_dir / \"logs\"\n",
        "        self.output_dir = self.base_dir / \"output\"\n",
        "        for dir_path in [self.input_dir, self.logs_dir, self.output_dir]:\n",
        "            dir_path.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "config = Config()\n",
        "print(\"Config initialized:\", config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d5d0c1",
      "metadata": {
        "id": "e5d5d0c1"
      },
      "source": [
        "## 2. Logging Initialization\n",
        "\n",
        "Set up logging to both file and console, and verify that logging output works as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5759de13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5759de13",
        "outputId": "7bc7adb3-85c0-4b9e-81d9-6e87ffb69885"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "def setup_logging():\n",
        "    log_file = config.logs_dir / f'pipeline_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log'\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
        "    file_handler = logging.FileHandler(log_file)\n",
        "    file_handler.setLevel(logging.DEBUG)\n",
        "    file_handler.setFormatter(formatter)\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "    console_handler.setFormatter(formatter)\n",
        "    logger = logging.getLogger(\"etl_notebook\")\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "    if not logger.handlers:\n",
        "        logger.addHandler(file_handler)\n",
        "        logger.addHandler(console_handler)\n",
        "    return logger\n",
        "\n",
        "logger = setup_logging()\n",
        "logger.info(\"Logging initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b6eb45a",
      "metadata": {
        "id": "6b6eb45a"
      },
      "source": [
        "## 3. Pydantic Schema Definitions\n",
        "\n",
        "Define the Pydantic models for Institution, Program, and ExtractionResult. Validate example data to demonstrate schema usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab5b2659",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab5b2659",
        "outputId": "3fdb8fe6-4a96-4bb1-b71b-6215b563997f"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from pydantic import BaseModel, Field, ConfigDict\n",
        "except ImportError:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pydantic\"])\n",
        "    from pydantic import BaseModel, Field, ConfigDict\n",
        "from typing import Optional, List, Dict, Any\n",
        "from datetime import datetime\n",
        "\n",
        "class Institution(BaseModel):\n",
        "    name: str = Field(..., description=\"Official institution name\")\n",
        "    institution_code: Optional[str] = Field(None, description=\"Unique identifier\")\n",
        "    description: Optional[str] = Field(None, description=\"Institution overview\")\n",
        "    type: List[str] = Field(default_factory=list, description=\"Institution types\")\n",
        "    country: str = Field(default=\"Sri Lanka\", description=\"Country\")\n",
        "    website: Optional[str] = Field(None, description=\"Website URL\")\n",
        "    recognition: Optional[Dict[str, Any]] = Field(None, description=\"Accreditation\")\n",
        "    contact_info: Optional[Dict[str, Any]] = Field(None, description=\"Contact details\")\n",
        "    confidence_score: float = Field(..., ge=0.0, le=1.0, description=\"Confidence (0-1)\")\n",
        "    model_config = ConfigDict(extra=\"forbid\")\n",
        "\n",
        "class Program(BaseModel):\n",
        "    name: str = Field(..., description=\"Program name\")\n",
        "    program_code: Optional[str] = Field(None, description=\"Unique identifier\")\n",
        "    description: Optional[str] = Field(None, description=\"Program overview\")\n",
        "    level: Optional[str] = Field(None, description=\"Academic level\")\n",
        "    duration: Optional[Dict[str, Any]] = Field(None, description=\"Duration details\")\n",
        "    delivery_mode: Optional[List[str]] = Field(None, description=\"Delivery modes\")\n",
        "    fees: Optional[Dict[str, Any]] = Field(None, description=\"Fee structure\")\n",
        "    eligibility: Optional[Dict[str, Any]] = Field(None, description=\"Requirements\")\n",
        "    curriculum_summary: Optional[str] = Field(None, description=\"Curriculum overview\")\n",
        "    specializations: Optional[List[str]] = Field(None, description=\"Specializations\")\n",
        "    extensions: Optional[Dict[str, Any]] = Field(None, description=\"Additional data\")\n",
        "    confidence_score: float = Field(..., ge=0.0, le=1.0, description=\"Confidence (0-1)\")\n",
        "    model_config = ConfigDict(extra=\"forbid\")\n",
        "\n",
        "class ExtractionResult(BaseModel):\n",
        "    institution: Institution\n",
        "    programs: List[Program] = Field(default_factory=list)\n",
        "    raw_text: str = Field(..., description=\"Original text\")\n",
        "    extraction_timestamp: datetime = Field(default_factory=datetime.now)\n",
        "    source_file: Optional[str] = Field(None, description=\"Source filename\")\n",
        "    model_config = ConfigDict(extra=\"allow\")\n",
        "\n",
        "# Example validation\n",
        "test_inst = Institution(name=\"Test University\", confidence_score=0.95)\n",
        "test_prog = Program(name=\"BSc Computer Science\", confidence_score=0.9)\n",
        "test_result = ExtractionResult(institution=test_inst, programs=[test_prog], raw_text=\"Sample text\")\n",
        "print(\"Validated ExtractionResult:\", test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e15c475",
      "metadata": {
        "id": "9e15c475"
      },
      "source": [
        "## 4. Ollama LLM Client Usage\n",
        "\n",
        "Instantiate the OllamaClient, test the connection, and demonstrate making a sample prompt call to the LLM. This section shows how to interact with the LLM for data extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BmHwXsIkZ6ZF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmHwXsIkZ6ZF",
        "outputId": "7b22df96-d839-4952-9815-edae0c5d61bd"
      },
      "outputs": [],
      "source": [
        "# Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"ðŸ“ Running in Google Colab - Installing Ollama...\")\n",
        "    # Install Ollama in Colab\n",
        "    !curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "    # Start Ollama server in background\n",
        "    import subprocess\n",
        "    import time\n",
        "\n",
        "    # Start server\n",
        "    ollama_process = subprocess.Popen(['ollama', 'serve'],\n",
        "                                      stdout=subprocess.PIPE,\n",
        "                                      stderr=subprocess.PIPE)\n",
        "    time.sleep(5)  # Wait for server to start\n",
        "\n",
        "    # Pull LLaMA 3 model\n",
        "    !ollama pull llama3\n",
        "\n",
        "    print(\"âœ… Ollama installed and started successfully!\")\n",
        "else:\n",
        "    print(\"ðŸ“ Running locally - Please ensure Ollama is installed and running\")\n",
        "    print(\"   Install: curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "    print(\"   Start server: ollama serve\")\n",
        "    print(\"   Pull model: ollama pull llama3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d99ae58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d99ae58",
        "outputId": "5c896007-f808-4760-f35f-d50be5fcbd4a"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import requests\n",
        "except ImportError:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"requests\"])\n",
        "    import requests\n",
        "import re, json\n",
        "\n",
        "class OllamaClient:\n",
        "    def __init__(self):\n",
        "        self.base_url = config.ollama_base_url\n",
        "        self.model = config.ollama_model\n",
        "        self.api_url = f\"{self.base_url}/api/generate\"\n",
        "    def call(self, prompt: str) -> dict:\n",
        "        response = requests.post(\n",
        "            self.api_url,\n",
        "            json={\n",
        "                \"model\": self.model,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False,\n",
        "                \"temperature\": config.ollama_temperature,\n",
        "                \"options\": {\"num_predict\": 4096, \"top_k\": 40, \"top_p\": 0.9}\n",
        "            },\n",
        "            timeout=config.ollama_timeout\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        raw_text = response.json().get(\"response\", \"\")\n",
        "        cleaned = re.sub(r'```json\\\\s*', '', raw_text)\n",
        "        cleaned = re.sub(r'```\\\\s*', '', cleaned)\n",
        "        match = re.search(r'\\{.*\\}', cleaned, re.DOTALL)\n",
        "        return json.loads(match.group(0) if match else cleaned.strip())\n",
        "    def test_connection(self) -> bool:\n",
        "        try:\n",
        "            response = requests.get(f\"{self.base_url}/api/tags\", timeout=5)\n",
        "            return response.status_code == 200\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "ollama = OllamaClient()\n",
        "print(\"Ollama connection:\", \"OK\" if ollama.test_connection() else \"FAILED\")\n",
        "\n",
        "# Example LLM call (replace with real prompt for actual use)\n",
        "# sample_prompt = \"{\"institution\": {\"name\": \"Test U\", \"confidence_score\": 1.0}, \"programs\": []}\"\n",
        "# print(ollama.call(sample_prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f16931e",
      "metadata": {
        "id": "2f16931e"
      },
      "source": [
        "## 5. Text Chunking and Cleaning\n",
        "\n",
        "Use the TextChunker class to clean and split a sample text into chunks, demonstrating the chunking logic used in the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec3e09fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec3e09fe",
        "outputId": "55bc01ad-4369-4efe-b3f4-2340d6880759"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "class TextChunker:\n",
        "    def __init__(self):\n",
        "        self.max_chars = config.chunk_max_chars\n",
        "        self.overlap = config.chunk_overlap\n",
        "    def chunk_text(self, text: str):\n",
        "        if len(text) <= self.max_chars:\n",
        "            return [text]\n",
        "        chunks, current = [], \"\"\n",
        "        paragraphs = text.split('\\n\\n')\n",
        "        for para in paragraphs:\n",
        "            if len(para) > self.max_chars:\n",
        "                sentences = para.split('. ')\n",
        "                for sent in sentences:\n",
        "                    if len(current) + len(sent) + 2 <= self.max_chars:\n",
        "                        current += sent + '. '\n",
        "                    else:\n",
        "                        if current:\n",
        "                            chunks.append(current.strip())\n",
        "                            current = current[-self.overlap:] + sent + '. '\n",
        "                        else:\n",
        "                            current = sent + '. '\n",
        "            else:\n",
        "                if len(current) + len(para) + 2 <= self.max_chars:\n",
        "                    current += para + '\\n\\n'\n",
        "                else:\n",
        "                    if current:\n",
        "                        chunks.append(current.strip())\n",
        "                        current = current[-self.overlap:] + para + '\\n\\n'\n",
        "                    else:\n",
        "                        current = para + '\\n\\n'\n",
        "        if current:\n",
        "            chunks.append(current.strip())\n",
        "        return chunks\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'[^\\w\\s\\.\\,\\:\\;\\-\\(\\)\\[\\]\\/\\&]', '', text)\n",
        "        return text.strip()\n",
        "\n",
        "chunker = TextChunker()\n",
        "sample_text = \"\"\"This is a sample educational program.\\n\\nIt covers multiple topics.\\n\\nThe duration is 3 years.\\n\\n\"\"\"\n",
        "cleaned = chunker.clean_text(sample_text)\n",
        "chunks = chunker.chunk_text(cleaned)\n",
        "print(\"Chunks:\", chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e96ac08",
      "metadata": {
        "id": "0e96ac08"
      },
      "source": [
        "## 6. Data Validation and Confidence Scoring\n",
        "\n",
        "Validate a sample extraction result using DataValidator, and normalize confidence scores with ConfidenceScorer. This ensures extracted data meets schema and quality requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3ca22f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d3ca22f",
        "outputId": "3a9ee71f-5f17-45e9-9014-2757e8e60784"
      },
      "outputs": [],
      "source": [
        "class DataValidator:\n",
        "    @staticmethod\n",
        "    def validate_extraction(data: dict, source_file: str = None):\n",
        "        if source_file:\n",
        "            data['source_file'] = source_file\n",
        "        result = ExtractionResult(**data)\n",
        "        logger.info(f\"Validation passed: {result.institution.name}\")\n",
        "        logger.info(f\"Programs: {len(result.programs)}\")\n",
        "        return result\n",
        "    @staticmethod\n",
        "    def validate_confidence(result: ExtractionResult) -> bool:\n",
        "        min_conf = config.confidence_threshold\n",
        "        if result.institution.confidence_score < min_conf:\n",
        "            logger.warning(f\"Low institution confidence: {result.institution.confidence_score}\")\n",
        "            return False\n",
        "        low_progs = [p.name for p in result.programs if p.confidence_score < min_conf]\n",
        "        if low_progs:\n",
        "            logger.warning(f\"Low confidence programs: {len(low_progs)}\")\n",
        "        return True\n",
        "\n",
        "class ConfidenceScorer:\n",
        "    def normalize_confidence(self, result: ExtractionResult) -> ExtractionResult:\n",
        "        result.institution.confidence_score = self._normalize_institution(result.institution)\n",
        "        for program in result.programs:\n",
        "            program.confidence_score = self._normalize_program(program)\n",
        "        return result\n",
        "    def _normalize_institution(self, inst: Institution) -> float:\n",
        "        score = inst.confidence_score\n",
        "        if score < config.confidence_threshold:\n",
        "            score *= 0.9\n",
        "        if not inst.website:\n",
        "            score *= 0.95\n",
        "        if not inst.institution_code:\n",
        "            score *= 0.98\n",
        "        return round(min(score, 1.0), 3)\n",
        "    def _normalize_program(self, prog: Program) -> float:\n",
        "        score = prog.confidence_score\n",
        "        if score < config.confidence_threshold:\n",
        "            score *= 0.85\n",
        "        missing = sum([not prog.level, not prog.duration, not prog.curriculum_summary])\n",
        "        score *= (1.0 - 0.03 * missing)\n",
        "        return round(min(score, 1.0), 3)\n",
        "\n",
        "# Example usage\n",
        "validator = DataValidator()\n",
        "scorer = ConfidenceScorer()\n",
        "\n",
        "sample_data = {\n",
        "    'institution': {'name': 'Test U', 'confidence_score': 0.7},\n",
        "    'programs': [{'name': 'BSc CS', 'confidence_score': 0.5}],\n",
        "    'raw_text': 'test'\n",
        "}\n",
        "result = validator.validate_extraction(sample_data)\n",
        "result = scorer.normalize_confidence(result)\n",
        "validator.validate_confidence(result)\n",
        "print(\"Normalized institution confidence:\", result.institution.confidence_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "537dcba8",
      "metadata": {
        "id": "537dcba8"
      },
      "source": [
        "## 7. MongoDB Writer Operations\n",
        "\n",
        "Connect to MongoDB, insert a sample ExtractionResult, and retrieve database statistics using MongoDBWriter. This demonstrates database integration for storing extracted data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a90c1574",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a90c1574",
        "outputId": "3b356aee-abe9-494c-f87b-86388d0a8d15"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from pymongo import MongoClient, errors\n",
        "    from pymongo.server_api import ServerApi\n",
        "except ImportError:\n",
        "    import sys, subprocess\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pymongo[srv]\"])\n",
        "    from pymongo import MongoClient, errors\n",
        "    from pymongo.server_api import ServerApi\n",
        "from datetime import datetime\n",
        "\n",
        "class MongoDBWriter:\n",
        "    def __init__(self):\n",
        "        self.client = MongoClient(\n",
        "            config.mongodb_uri,\n",
        "            server_api=ServerApi('1'),\n",
        "            serverSelectionTimeoutMS=5000\n",
        "        )\n",
        "        self.client.admin.command('ping')\n",
        "        self.db = self.client[config.database_name]\n",
        "        self.institutions = self.db.institutions\n",
        "        self.programs = self.db.programs\n",
        "        self.raw_documents = self.db.raw_documents\n",
        "        self.extraction_logs = self.db.extraction_logs\n",
        "        self._create_indexes()\n",
        "    def _create_indexes(self):\n",
        "        self.institutions.create_index(\"name\")\n",
        "        self.institutions.create_index(\n",
        "            \"institution_code\", unique=True,\n",
        "            partialFilterExpression={\"institution_code\": {\"$type\": \"string\"}}\n",
        "        )\n",
        "        self.programs.create_index(\"institution_id\")\n",
        "        self.programs.create_index(\"name\")\n",
        "        self.programs.create_index(\"level\")\n",
        "    def write_extraction(self, result: ExtractionResult) -> dict:\n",
        "        inst_data = result.institution.model_dump()\n",
        "        inst_data['inserted_at'] = datetime.now()\n",
        "        if inst_data.get('institution_code') is None:\n",
        "            inst_data.pop('institution_code', None)\n",
        "        inst_result = self.institutions.insert_one(inst_data)\n",
        "        inst_id = inst_result.inserted_id\n",
        "        prog_ids = []\n",
        "        for program in result.programs:\n",
        "            prog_data = program.model_dump()\n",
        "            prog_data['institution_id'] = inst_id\n",
        "            prog_data['inserted_at'] = datetime.now()\n",
        "            prog_result = self.programs.insert_one(prog_data)\n",
        "            prog_ids.append(prog_result.inserted_id)\n",
        "        raw_doc = {\n",
        "            'institution_id': inst_id,\n",
        "            'raw_text': result.raw_text[:5000],\n",
        "            'source_file': result.source_file,\n",
        "            'extraction_timestamp': result.extraction_timestamp,\n",
        "            'inserted_at': datetime.now()\n",
        "        }\n",
        "        raw_result = self.raw_documents.insert_one(raw_doc)\n",
        "        self.extraction_logs.insert_one({\n",
        "            'institution_id': inst_id,\n",
        "            'source_file': result.source_file,\n",
        "            'programs_count': len(result.programs),\n",
        "            'institution_confidence': result.institution.confidence_score,\n",
        "            'avg_program_confidence': sum(p.confidence_score for p in result.programs) / len(result.programs) if result.programs else 0,\n",
        "            'timestamp': datetime.now(),\n",
        "            'status': 'success'\n",
        "        })\n",
        "        return {'institution_id': inst_id, 'program_ids': prog_ids, 'raw_document_id': raw_result.inserted_id}\n",
        "    def get_statistics(self):\n",
        "        return {\n",
        "            'institutions': self.institutions.count_documents({}),\n",
        "            'programs': self.programs.count_documents({}),\n",
        "            'raw_documents': self.raw_documents.count_documents({}),\n",
        "            'extraction_logs': self.extraction_logs.count_documents({})\n",
        "        }\n",
        "    def close(self):\n",
        "        self.client.close()\n",
        "\n",
        "# Example usage\n",
        "try:\n",
        "    mongo = MongoDBWriter()\n",
        "    inserted = mongo.write_extraction(result)\n",
        "    print(\"Inserted IDs:\", inserted)\n",
        "    print(\"DB stats:\", mongo.get_statistics())\n",
        "    mongo.close()\n",
        "except Exception as e:\n",
        "    print(\"MongoDB error:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aeaa406",
      "metadata": {
        "id": "3aeaa406"
      },
      "source": [
        "## 8. Prompt Template Construction\n",
        "\n",
        "Show how to construct system and user prompts for LLM extraction using the provided templates. This ensures the LLM receives clear, schema-aligned instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e2de23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35e2de23",
        "outputId": "05f6ceb1-f9dd-4bad-a8ca-64caaa5f22fc"
      },
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"You are a structured data extraction engine for educational institutions.\n",
        "\n",
        "YOUR TASK:\n",
        "CRITICAL RULES (NON-NEGOTIABLE):\n",
        "1. Output ONLY a single valid JSON object\n",
        "2. NO markdown, NO code blocks, NO explanations, NO comments\n",
        "3. Follow the JSON schema EXACTLY\n",
        "4. Do NOT invent, guess, normalize, or enrich data\n",
        "5. If a field is not explicitly stated or clearly implied, OMIT it\n",
        "6. Preserve original wording as closely as possible\n",
        "7. Use null ONLY if the schema explicitly allows Optional fields (otherwise omit)\n",
        "8. All confidence_score values MUST be between 0.0 and 1.0\n",
        "\n",
        "SCHEMA CONSTRAINTS:\n",
        "- Root object MUST contain:\n",
        "  - institution (object)\n",
        "  - programs (array)\n",
        "  - raw_text (string)\n",
        "\n",
        "- Do NOT add fields that are not defined in the schema\n",
        "- Do NOT add empty objects or empty arrays\n",
        "- extra fields inside Institution and Program are FORBIDDEN\n",
        "\n",
        "FIELD-SPECIFIC RULES:\n",
        "- institution.type: array of strings only (e.g., [\"University\", \"Private Institute\"])\n",
        "- programs.duration, fees, eligibility, recognition, contact_info:\n",
        "  - Must be JSON objects derived directly from the source text\n",
        "  - Use key-value pairs that reflect the wording in the content\n",
        "- delivery_mode and specializations:\n",
        "  - Use arrays ONLY if multiple items are explicitly stated\n",
        "\n",
        "CONFIDENCE SCORING GUIDELINES:\n",
        "- 1.0 â†’ Explicitly stated, exact wording\n",
        "- 0.8â€“0.9 â†’ Clearly stated with minimal ambiguity\n",
        "- 0.6â€“0.7 â†’ Partially stated or implied\n",
        "- 0.4â€“0.5 â†’ Weak contextual inference\n",
        "- 0.0â€“0.3 â†’ Very uncertain (use sparingly)\n",
        "\n",
        "IMPORTANT:\n",
        "- If confidence is below 0.4, consider OMITTING the field instead\n",
        "- Each institution and program MUST include a confidence_score\n",
        "- raw_text MUST contain the full, unmodified source content\n",
        "\n",
        "FAILURE CONDITIONS (AVOID):\n",
        "- Invalid JSON\n",
        "- Missing required fields\n",
        "- Hallucinated facts\n",
        "- Schema violations\n",
        "object_type\n",
        "institute\n",
        "skip\n",
        "program\n",
        "skip\n",
        "skip\n",
        "\"\"\"\n",
        "\n",
        "USER_PROMPT_TEMPLATE = \"\"\" Extract structured educational data from the source content below.\n",
        "\n",
        "SOURCE CONTENT:\n",
        "<<<\n",
        "{content}\n",
        ">>>\n",
        "\n",
        "RESPONSE REQUIREMENTS:\n",
        "- Return ONLY the JSON object\n",
        "- Follow the schema and system rules strictly\n",
        "- Do not include explanations or formatting\n",
        "\"\"\"\n",
        "\n",
        "# Example prompt construction\n",
        "sample_content = \"Sample university offers a BSc in Computer Science.\"\n",
        "prompt = SYSTEM_PROMPT + USER_PROMPT_TEMPLATE.format(content=sample_content)\n",
        "print(prompt[:400] + \"...\\n[truncated]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "532fd61f",
      "metadata": {
        "id": "532fd61f"
      },
      "source": [
        "## 9. Extraction Pipeline Execution\n",
        "\n",
        "Run the ExtractionPipeline on a sample text file, demonstrating the full ETL process for a single file. This section ties together all previous components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import traceback\n",
        "class ExtractionPipeline:\n",
        "    def __init__(self):\n",
        "        self.ollama = OllamaClient()\n",
        "        self.chunker = TextChunker()\n",
        "        self.validator = DataValidator()\n",
        "        self.scorer = ConfidenceScorer()\n",
        "        try:\n",
        "            self.mongo = MongoDBWriter()\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"MongoDB not available: {e}\")\n",
        "            self.mongo = None\n",
        "    def process_file(self, file_path, save_to_db=True):\n",
        "        logger.info(f\"Processing: {file_path}\")\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                text = f.read()\n",
        "            text = self.chunker.clean_text(text)\n",
        "            chunks = self.chunker.chunk_text(text)\n",
        "            global institution_name\n",
        "            global _institution_id\n",
        "            for chunk in chunks:\n",
        "                prompt = SYSTEM_PROMPT + USER_PROMPT_TEMPLATE.format(institution_name=institution_name, content=chunk)\n",
        "                try:\n",
        "                    response = self.ollama.call(prompt)\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"LLM call failed: {e}\")\n",
        "                    continue\n",
        "                obj_type = response.get('object_type')\n",
        "                if obj_type == 'skip':\n",
        "                    logger.info(f\"File {file_path} skipped (no relevant data)\")\n",
        "                    return None\n",
        "                elif obj_type == 'program':\n",
        "                    # Save program, link to institution\n",
        "                    if self.mongo and _institution_id is not None:\n",
        "                        prog_data = response.copy()\n",
        "                        prog_data.pop('object_type', None)\n",
        "                        prog_data['institution_id'] = _institution_id\n",
        "                        prog_data['inserted_at'] = datetime.now()\n",
        "                        self.mongo.programs.insert_one(prog_data)\n",
        "                        logger.info(f\"Program saved for institution {_institution_id}\")\n",
        "                    return response\n",
        "                elif obj_type == 'institute':\n",
        "                    # Create or update institution\n",
        "                    inst_data = response.copy()\n",
        "                    inst_data.pop('object_type', None)\n",
        "                    if self.mongo:\n",
        "                        if '_institution_id' not in globals() or _institution_id is None:\n",
        "                            # First time: create institution\n",
        "                            inst_data['inserted_at'] = datetime.now()\n",
        "                            result = self.mongo.institutions.insert_one(inst_data)\n",
        "                            _institution_id = result.inserted_id\n",
        "                            logger.info(f\"Institution created with id {_institution_id}\")\n",
        "                        else:\n",
        "                            # Update institution\n",
        "                            self.mongo.institutions.update_one({'_id': _institution_id}, {'$set': inst_data})\n",
        "                            logger.info(f\"Institution updated for id {_institution_id}\")\n",
        "                    return response\n",
        "                else:\n",
        "                    logger.warning(f\"Unknown object_type in response: {obj_type}\")\n",
        "                    return None\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Pipeline failed: {e}\")\n",
        "            logger.error(traceback.format_exc())\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94959706",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === 10. Run Batch ETL for One Institution ===\n",
        "\n",
        "# Prompt for institution name, select files, and run the batch processor.\n",
        "from pathlib import Path\n",
        "\n",
        "# Prompt for institution name (if not already set)\n",
        "try:\n",
        "\n",
        "    institution_name = institution_name\n",
        "\n",
        "except NameError:\n",
        "\n",
        "    institution_name = input(\"Enter the institution name for this batch: \")\n",
        "\n",
        "    print(f\"Institution name set to: {institution_name}\")\n",
        "\n",
        "\n",
        "# List all .txt files in the input directory\n",
        "input_dir = config.input_dir\n",
        "\n",
        "all_files = sorted([str(f) for f in Path(input_dir).glob(\"*.txt\")])\n",
        "\n",
        "print(f\"Found {len(all_files)} files in {input_dir}\")\n",
        "\n",
        "\n",
        "# Optionally, filter files for this institution (by name or manual selection)\n",
        "\n",
        "# For now, process all files in the input directory.\n",
        "files_to_process = all_files\n",
        "\n",
        "\n",
        "# Initialize pipeline and batch processor\n",
        "pipeline = ExtractionPipeline()\n",
        "\n",
        "batch = BatchProcessor(pipeline)\n",
        "\n",
        "\n",
        "# Run batch processing (one institution per batch)\n",
        "\n",
        "batch.process_all(files_to_process, save_to_db=True)\n",
        "\n",
        "\n",
        "# Show summary\n",
        "\n",
        "print(\"Batch processing complete.\")\n",
        "\n",
        "print(\"Success:\", batch.results['success'])\n",
        "\n",
        "print(\"Failed:\", batch.results['failed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cbe949e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "class BatchProcessor:\n",
        "    def __init__(self, pipeline):\n",
        "        self.pipeline = pipeline\n",
        "        self.results = {'success': [], 'failed': []}\n",
        "    def process_all(self, files, save_to_db=True):\n",
        "        global _institution_id\n",
        "        _institution_id = None  # Reset institution id for new batch\n",
        "        total = len(files)\n",
        "        logger.info(f\"BATCH PROCESSING: {total} files\")\n",
        "        start_time = time.time()\n",
        "        for idx, file_path in enumerate(files, 1):\n",
        "            logger.info(f\"[{idx}/{total}] Processing: {file_path}\")\n",
        "            result = self._process_with_retry(file_path, save_to_db)\n",
        "            if result:\n",
        "                self.results['success'].append(str(file_path))\n",
        "                logger.info(\"Success\")\n",
        "            else:\n",
        "                self.results['failed'].append(str(file_path))\n",
        "                logger.info(\"Failed\")\n",
        "            success_rate = len(self.results['success']) / idx * 100\n",
        "            logger.info(f\"Progress: {idx}/{total} ({success_rate:.1f}% success)\")\n",
        "        self._print_summary(time.time() - start_time)\n",
        "    def _process_with_retry(self, file_path, save_to_db):\n",
        "        for attempt in range(config.max_retries + 1):\n",
        "            try:\n",
        "                result = self.pipeline.process_file(file_path, save_to_db)\n",
        "                if result:\n",
        "                    return result\n",
        "                if attempt < config.max_retries:\n",
        "                    logger.warning(f\"Retry {attempt + 1}/{config.max_retries}\")\n",
        "                    time.sleep(config.retry_delay)\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Attempt {attempt + 1} failed: {e}\")\n",
        "                if attempt < config.max_retries:\n",
        "                    time.sleep(config.retry_delay)\n",
        "        return None\n",
        "    def _print_summary(self, elapsed):\n",
        "        total = len(self.results['success']) + len(self.results['failed'])\n",
        "        success_count = len(self.results['success'])\n",
        "        logger.info(f\"BATCH PROCESSING COMPLETE\\nSummary: Total: {total}, Success: {success_count}, Failed: {len(self.results['failed'])}, Time: {elapsed:.1f}s\")\n",
        "        if self.results['failed']:\n",
        "            logger.info(\"Failed files: \" + \", \".join(self.results['failed']))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
